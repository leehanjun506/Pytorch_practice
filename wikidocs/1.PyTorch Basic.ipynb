{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cfe00f0",
   "metadata": {},
   "source": [
    "# PyTorch Basic\n",
    "---\n",
    "  \n",
    "  \n",
    "## 1. 파이토치 패키지의 기본 구성\n",
    "#### 1. torch  \n",
    "메인 네임스페이스. 텐서 등의 다양한 수학 함수 포함\n",
    "#### 2. torch.autograd  \n",
    "자동 미분을 위한 함수들이 포함되어져 있다.\n",
    "#### 3. torch.nn\n",
    "신경망을 구축하기 위한 다양한 데이터 구조나 레이어 등이 정의되어져 있다.  \n",
    "예를 들어 RNN, LSTM 과 같은 레이어, ReLU와 같은 활성화 함수, MSELose와 같은 손실 함수들이 있다.\n",
    "#### 4. torch.optim\n",
    "확률적 경사 하강법(Stochastic Gradient Descent,SGD)를 중심으로 한 파라미터 최적화 알고리즘이 구현되어져 있다.\n",
    "#### 5. torch.utils.data\n",
    "SGD의 반복 연산을 실행할 때 사용하는 미니 배치용 유틸리티 함수가 포함되어져 있다.\n",
    "#### 6. torch.onnx\n",
    "ONNX(Open Neural Network Exchange)의 포맷으로 모델을 export 할 때 사용한다.    \n",
    "ONNX는 서로 다른 딥러닝 프레임워크 간에 모델을 공유할 때 사용하는 포맷이다.  \n",
    "<br/><br/>\n",
    "## 2. 텐서 조작하기(Tensor Manipulation)\n",
    "\n",
    "### 1. 텐서 선언하기(PyTorch Tensor Allocation)\n",
    "#### 1) 1D with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c3df5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3., 4., 5., 6.])\n",
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n",
      "tensor(0.) tensor(1.) tensor(6.)\n",
      "tensor([2., 3., 4.]) tensor([4., 5.])\n",
      "tensor([0., 1.]) tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "t = torch.FloatTensor([0,1,2,3,4,5,6])\n",
    "print(t)\n",
    "print(t.dim()) # rank 즉, 차원\n",
    "print(t.shape) # shape\n",
    "print(t.size()) # shape\n",
    "\n",
    "print(t[0],t[1],t[-1]) # 인덱스로 접근\n",
    "print(t[2:5],t[4:-1]) # 슬라이싱\n",
    "print(t[:2],t[3:]) # 슬라이싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b52dd05",
   "metadata": {},
   "source": [
    "#### 2) 2D with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d209f680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "2\n",
      "torch.Size([4, 3])\n",
      "tensor([ 2.,  5.,  8., 11.])\n",
      "torch.Size([4])\n",
      "tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(t)\n",
    "\n",
    "print(t.dim()) # rank. 즉, 차원\n",
    "print(t.size()) # shape\n",
    "\n",
    "print(t[:,1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원의 첫번째 것만 가져옴.\n",
    "print(t[:,1].size()) # ↑ 위의 경우의 크기\n",
    "\n",
    "print(t[:,:-1]) # 첫번째 차원을 전체 선택한 상황에서 두번째 차원에서는 맨 마지막에서 첫번째를 제외하고 다 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690476de",
   "metadata": {},
   "source": [
    "#### 3) 브로드캐스팅(Broadcasting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22733b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 5.]])\n",
      "tensor([[4., 5.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2]])\n",
    "m2 = torch.FloatTensor([3])\n",
    "print(m1+m2)\n",
    "\n",
    "m3 = torch.FloatTensor([[1,2]])\n",
    "m4 = torch.FloatTensor([[3],[4]])\n",
    "print(m3+m4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4fd9e5",
   "metadata": {},
   "source": [
    "딥 러닝을 하게되면 크기가 다른 행렬 또는 텐서에 대해서 사칙 연산을 수행할 필요가 있다.  \n",
    "이를 위해 파이토치에서는 자동으로 크기를 맞춰 연산을 수행하게 만드는 **브로드캐스팅**이라는 기능을 제공한다.\n",
    "#### 4) 자주 사용되는 기능들\n",
    "#### 1. 행렬 곱셈과 곱셈의 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c2c6b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Matrix 1: torch.Size([2, 2])\n",
      "Shape of Matrix 2: torch.Size([2, 1])\n",
      "tensor([[ 5.],\n",
      "        [11.]])\n",
      "tensor([[1., 2.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "m1 = torch.FloatTensor([[1,2],[3,4]])\n",
    "m2 = torch.FloatTensor([[1],[2]])\n",
    "\n",
    "print('Shape of Matrix 1: {}'.format(m1.shape))\n",
    "print('Shape of Matrix 2: {}'.format(m2.shape))\n",
    "\n",
    "print(m1.matmul(m2)) # Matrix Multiplication\n",
    "print(m1*m2) # Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43e0560",
   "metadata": {},
   "source": [
    "#### 2. 평균(Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c2826f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5000)\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([1,2])\n",
    "print(t.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47a06287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(2.5000)\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "print(t.mean())\n",
    "\n",
    "print(t.mean(dim=0)) # dim에 해당하는 차원을 제거\n",
    "print(t.mean(dim=1))\n",
    "print(t.mean(dim=-1)) # 마지막 차원 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8ecf6b",
   "metadata": {},
   "source": [
    "#### 3. 덧셈(Sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb2307b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(10.)\n",
      "tensor([4., 6.])\n",
      "tensor([3., 7.])\n",
      "tensor([3., 7.])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "\n",
    "print(t.sum())\n",
    "print(t.sum(dim=0))\n",
    "print(t.sum(dim=1))\n",
    "print(t.sum(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8044228e",
   "metadata": {},
   "source": [
    "#### 4. 최대(Max)와 아그맥스(ArgMax)\n",
    "max에 dim인자를 주면 argmax도 함께 리턴하는 특징이 있다.  \n",
    "만약 max 또는 argmax만 리턴받고 싶다면 리턴값에도 인덱스를 부여하면 된다.  \n",
    "0번 인덱스를 사용하면 max값, 1번 인덱스를 사용하면 argmax값만 받아올 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "846c40e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor(4.)\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 4.]),\n",
      "indices=tensor([1, 1]))\n",
      "Max: tensor([3., 4.])\n",
      "Argmax: tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "t = torch.FloatTensor([[1,2],[3,4]])\n",
    "print(t)\n",
    "\n",
    "print(t.max())\n",
    "print(t.max(dim=0))\n",
    "\n",
    "print('Max: {}'.format(t.max(dim=0)[0]))\n",
    "print('Argmax: {}'.format(t.max(dim=1)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e95e7e",
   "metadata": {},
   "source": [
    "#### 5) 뷰(View) - 원소의 수를 유지하면서 텐서의 크기 변경\n",
    "넘파이에서의 reshape와 같은 역할을 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9932965f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.],\n",
      "         [ 9., 10., 11.]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "t = np.arange(12).reshape(2,2,3)\n",
    "ft = torch.FloatTensor(t)\n",
    "print(ft)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "316fdd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1,3])) # ft라는 텐서를 (?,3)의 크기로 변경\n",
    "print(ft.view([-1,3]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb46bc1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.]],\n",
      "\n",
      "        [[ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 6.,  7.,  8.]],\n",
      "\n",
      "        [[ 9., 10., 11.]]])\n",
      "torch.Size([4, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1,1,3]))\n",
    "print(ft.view([-1,1,3]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17a696",
   "metadata": {},
   "source": [
    "#### 6) 스퀴즈(Squeeze) - 차원이 1인 경우 해당 차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "686c5b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.FloatTensor([[0],[1],[2]])\n",
    "print(ft)\n",
    "print(ft.shape)\n",
    "\n",
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f80883",
   "metadata": {},
   "source": [
    "#### 7) 언스퀴즈(Unsqueeze) - 특정 위치에 1인 차원을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f88ab02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.Tensor([0,1,2])\n",
    "print(ft.shape)\n",
    "\n",
    "print(ft.unsqueeze(0)) # 첫번째 차원에 1인 차원이 추가\n",
    "print(ft.unsqueeze(0).shape)\n",
    "\n",
    "print(ft.unsqueeze(1)) \n",
    "print(ft.unsqueeze(1).shape)\n",
    "\n",
    "print(ft.unsqueeze(-1)) # 마지막 차원에 1인 차원이 추가\n",
    "print(ft.unsqueeze(-1).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b018d22f",
   "metadata": {},
   "source": [
    "#### 8) 타입 캐스팅(Type Casting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949c6f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4])\n",
      "tensor([1., 2., 3., 4.])\n",
      "tensor([1, 0, 0, 1], dtype=torch.uint8)\n",
      "tensor([1, 0, 0, 1])\n",
      "tensor([1., 0., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "lt = torch.LongTensor([1,2,3,4])\n",
    "print(lt)\n",
    "print(lt.float())\n",
    "\n",
    "bt = torch.ByteTensor([True,False,False,True])\n",
    "print(bt)\n",
    "\n",
    "print(bt.long())\n",
    "print(bt.float())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235751a",
   "metadata": {},
   "source": [
    "#### 9) 연결하기(concatenate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a885df8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.],\n",
      "        [7., 8.]])\n",
      "tensor([[1., 2., 5., 6.],\n",
      "        [3., 4., 7., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "y = torch.FloatTensor([[5,6],[7,8]])\n",
    "\n",
    "print(torch.cat([x,y],dim=0)) # 첫번째 차원을 늘림\n",
    "\n",
    "print(torch.cat([x,y],dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e9de26",
   "metadata": {},
   "source": [
    "#### 10) 스택킹(Stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7da729ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([1,4])\n",
    "y = torch.FloatTensor([2,5])\n",
    "z = torch.FloatTensor([3,6])\n",
    "\n",
    "print(torch.stack([x,y,z]))\n",
    "print(torch.cat([x.unsqueeze(0),y.unsqueeze(0),z.unsqueeze(0)],dim=0))\n",
    "\n",
    "print(torch.stack([x,y,z],dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db92c33",
   "metadata": {},
   "source": [
    "#### 11) ones_like , zeros_like - 0으로 채워진 텐서와 1로 채워진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68eb3866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [2., 1., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0,1,2],[2,1,0]])\n",
    "print(x)\n",
    "\n",
    "print(torch.ones_like(x))\n",
    "print(torch.zeros_like(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9c8280",
   "metadata": {},
   "source": [
    "#### 12) In-place Operation(덮어쓰기 연산)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3600e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2],[3,4]])\n",
    "\n",
    "print(x.mul(2.))\n",
    "print(x)\n",
    "\n",
    "print(x.mul_(2.)) # 연산 뒤에 _를 붙여 기존의 값을 덮어쓰기 함.\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
